{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34da72e0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./Images/hackathon1.png\" alt=\"HackThon\" height=\"900\" width=\"900\"/>\n",
    "\n",
    "## *Test case* : _Object Detection in the Image and Identify the postion of detected Objects with Voice Feedback_\n",
    "\n",
    "![A robot identifying fruit](./Images/object-detection.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPath = os.path.sep.join([\"coco.names\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1808c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LABELS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e570b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsPath = 'yolov3.weights'\n",
    "configPath = 'yolov3.cfg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d98270",
   "metadata": {},
   "outputs": [],
   "source": [
    "configPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da735d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ada5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test3.jpg')\n",
    "(H, W) = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfa51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781a78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "start = time.time()\n",
    "layerOutputs = net.forward(ln)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9689eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d156c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "confidences = []\n",
    "centers = []\n",
    "classIDs = []\n",
    "ID = 0\n",
    "font_scale = 3\n",
    "font = cv2.FONT_HERSHEY_PLAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f7ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for output in layerOutputs:\n",
    "\n",
    "\tfor detection in output:\n",
    "\n",
    "\t\tscores = detection[5:]\n",
    "\t\tclassID = np.argmax(scores)\n",
    "\t\tconfidence = scores[classID]\n",
    "\n",
    "\n",
    "\t\tif confidence > 0.5:\n",
    "\n",
    "\t\t\tbox = detection[0:4] * np.array([W, H, W, H])\n",
    "\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\tx = int(centerX - (width / 2))\n",
    "\t\t\ty = int(centerY - (height / 2))\n",
    "\n",
    "\n",
    "\t\t\tboxes.append([x, y, int(width), int(height)])\n",
    "\t\t\tconfidences.append(float(confidence))\n",
    "            \n",
    "\t\t\tclassIDs.append(classID)\n",
    "\t\t\tcenters.append((centerX, centerY))\n",
    "            \n",
    "x = classIDs\n",
    "\n",
    "#print(LABELS[classIDs[2]], confidences[2])\n",
    "\n",
    "idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5 ,0.3)\n",
    "\n",
    "\n",
    "if len(idxs) > 0:\n",
    "\tlist1 = []\n",
    "\tfor i in idxs.flatten():\n",
    "\n",
    "\t\t(x, y) = (boxes[i][0], boxes[i][1])\n",
    "\t\t(w, h) = (boxes[i][2], boxes[i][3])\n",
    "        \n",
    "#\t\tcenterX, centerY = centers[i][0], centers[i][1]\n",
    "\t\tcenterX = round((2*x + w)/2)\n",
    "\t\tcenterY = round((2*y + h)/2)\n",
    "\t\tif centerX <= W/3:\n",
    "\t\t\tW_pos = \"left \"\n",
    "\t\telif centerX <= (W/3 * 2):\n",
    "\t\t\tW_pos = \"center \"\n",
    "\t\telse:\n",
    "\t\t\tW_pos = \"right \"\n",
    "\n",
    "\t\tif centerY <= H/3:\n",
    "\t\t\tH_pos = \"top \"\n",
    "\t\telif centerY <= (H/3 * 2):\n",
    "\t\t\tH_pos = \"mid \"\n",
    "\t\telse:\n",
    "\t\t\tH_pos = \"bottom \"\n",
    "            \n",
    "        \n",
    "\t\tlist1.append(H_pos + W_pos + LABELS[classIDs[i]])\n",
    "        \n",
    "\t\tprint('\\n***************** object in image is Detected..... *****************\\n')\n",
    "        \n",
    "\t\tprint(LABELS[classIDs[i]], confidences[i])\n",
    "        \n",
    "\n",
    "        \n",
    "#\tplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\tdescription = ', '.join(list1)\n",
    "    \n",
    "\tprint('\\n***************** Detected Object Position in image are .... *****************\\n')\n",
    "\n",
    "\tmyobj = gTTS(text=description, lang=\"en\", slow=False)\n",
    "    \n",
    "\tprint('\"{}\"'.format(description))\n",
    "    \n",
    "\tprint('\\n***************** Text To Speech Conversion.... *****************\\n')\n",
    "    \n",
    "\tmyobj.save(\"object_detection.mp3\")\n",
    "    \n",
    "\tprint('----------------------- Done :) -------------------------------')\n",
    "    \n",
    "os.system('start object_detection.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e1805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ea586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\tclassIDs_1 = np.array(classIDs)\n",
    "\tconfidences_1 = np.array(confidences)\n",
    "\tfor ClassInd, conf , bbox in zip(classIDs_1.flatten(), confidences_1.flatten(), boxes):\n",
    "\t\tcv2.rectangle(image,bbox,(255, 100, 0), 2)\n",
    "\t\tcv2.putText(image,LABELS[ClassInd],(bbox[0]+10,bbox[1]+40), font, fontScale=font_scale,color=(0,255,0), thickness =3 )\n",
    "        \n",
    "\tplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e886e27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c7bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98884e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5c05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1694a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64f789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93622d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23e4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a1c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e36db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fee5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
